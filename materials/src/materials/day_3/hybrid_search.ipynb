{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e674d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "client = QdrantClient(\":memory:\") # Para testar rápido na memória\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"meu_projeto_hibrido\",\n",
    "    # Configuração para busca por Significado (Densa)\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=1536, # Ex: tamanho do embedding da OpenAI\n",
    "        distance=models.Distance.COSINE\n",
    "    ),\n",
    "    # Configuração para busca por Palavra-Chave (Esparsa)\n",
    "    sparse_vectors_config={\n",
    "        \"text-sparse\": models.SparseVectorParams(\n",
    "            index=models.SparseIndexParams(\n",
    "                on_disk=False,\n",
    "            )\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine que 'vetor_denso' e 'vetor_esparso' foram gerados pelos seus modelos\n",
    "resultado = client.query(\n",
    "    collection_name=\"meu_projeto_hibrido\",\n",
    "    prefetch=[\n",
    "        # Busca 1: Pelo significado (Dense)\n",
    "        models.Prefetch(\n",
    "            query=vetor_denso,\n",
    "            limit=20\n",
    "        ),\n",
    "        # Busca 2: Pela palavra exata (Sparse)\n",
    "        models.Prefetch(\n",
    "            query=vetor_esparso,\n",
    "            using=\"text-sparse\",\n",
    "            limit=20\n",
    "        ),\n",
    "    ],\n",
    "    # O \"RRF\" funde os dois rankings de forma inteligente\n",
    "    query_filter=None, \n",
    "    ranking=models.Fusion.RRF, \n",
    "    limit=5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
