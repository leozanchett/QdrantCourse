{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68e4de2",
   "metadata": {},
   "source": [
    "Primeiro, vamos preparar o ambiente e criar uma coleção otimizada para escala (como discutido no Day 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4854b9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, Batch, BinaryQuantization, BinaryQuantizationConfig\n",
    "\n",
    "client = QdrantClient(\":memory:\") # Usando memória para o exemplo, mas seria a URL do seu servidor\n",
    "\n",
    "# 1. Configuração Otimizada (Essencial para o Day 4)\n",
    "client.recreate_collection(\n",
    "    collection_name=\"escala_demo\",\n",
    "    vectors_config=VectorParams(size=128, distance=Distance.COSINE, on_disk=True), # Vetores no disco\n",
    "    quantization_config=BinaryQuantization(\n",
    "        binary=BinaryQuantizationConfig(always_ram=True) # Busca rápida na RAM\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933f182f",
   "metadata": {},
   "source": [
    "Abordagem 1: upsert com Batches (Até 100k pontos)\n",
    "\n",
    "Nesta abordagem, nós mesmos dividimos os dados em \"pacotes\" e enviamos. É o método mais flexível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1116bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_with_upsert(client, collection_name, total_points=1000):\n",
    "    batch_size = 100\n",
    "    for i in range(0, total_points, batch_size):\n",
    "        # Criando um lote (batch) de dados\n",
    "        ids = list(range(i, i + batch_size))\n",
    "        vectors = np.random.rand(batch_size, 128).tolist()\n",
    "        payloads = [{\"original_id\": j, \"tipo\": \"teste\"} for j in ids]\n",
    "\n",
    "        client.upsert(\n",
    "            collection_name=collection_name,\n",
    "            points=Batch(\n",
    "                ids=ids,\n",
    "                vectors=vectors,\n",
    "                payloads=payloads\n",
    "            )\n",
    "        )\n",
    "    print(f\"Ingestão de {total_points} concluída com upsert.\")\n",
    "\n",
    "ingest_with_upsert(client, \"escala_demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0dc065",
   "metadata": {},
   "source": [
    "Abordagem 2: upload_points (De 100k a 1M pontos)\n",
    "\n",
    "Este método é um \"atalho\" do cliente Python que gerencia os lotes internamente para você. É mais limpo, mas os dados precisam estar na memória do seu script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76475094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "def ingest_with_upload_points(client, collection_name, total_points=1000):\n",
    "    # Geramos todos os pontos primeiro (consome RAM no seu PC)\n",
    "    points = [\n",
    "        PointStruct(\n",
    "            id=i,\n",
    "            vector=np.random.rand(128).tolist(),\n",
    "            payload={\"meta\": \"dados_medios\"}\n",
    "        ) for i in range(1000, 1000 + total_points)\n",
    "    ]\n",
    "\n",
    "    client.upload_points(\n",
    "        collection_name=collection_name,\n",
    "        points=points,\n",
    "        batch_size=100,\n",
    "        parallel=2 # Começamos a usar paralelismo aqui\n",
    "    )\n",
    "    print(f\"Ingestão de {total_points} concluída com upload_points.\")\n",
    "\n",
    "ingest_with_upload_points(client, \"escala_demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ceeda5",
   "metadata": {},
   "source": [
    "Abordagem 3: upload_collection (O padrão ouro para > 1M pontos)\n",
    "\n",
    "Esta é a forma mais eficiente. Usamos um Gerador (Generator). Os dados não são carregados todos de uma vez; eles \"fluem\" do disco/banco de dados direto para o Qdrant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe610d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(total_points):\n",
    "    \"\"\"Simula a leitura de um arquivo gigante linha por linha\"\"\"\n",
    "    for i in range(5000, 5000 + total_points):\n",
    "        yield PointStruct(\n",
    "            id=i,\n",
    "            vector=np.random.rand(128).tolist(),\n",
    "            payload={\"status\": \"streaming\"}\n",
    "        )\n",
    "\n",
    "def ingest_large_scale(client, collection_name):\n",
    "    # O método upload_collection aceita um iterador/gerador\n",
    "    client.upload_collection(\n",
    "        collection_name=collection_name,\n",
    "        points=data_generator(10000), # Pode ser milhões aqui\n",
    "        batch_size=256,\n",
    "        parallel=4, # Usa 4 núcleos do processador para enviar em paralelo\n",
    "    )\n",
    "    print(\"Ingestão de larga escala concluída com streaming e paralelismo.\")\n",
    "\n",
    "ingest_large_scale(client, \"escala_demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575ceb8",
   "metadata": {},
   "source": [
    "## Resumo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b897bb82",
   "metadata": {},
   "source": [
    "Resumo das Diferenças no Código:\n",
    "Memória: No upload_points, você passa uma list[] (pesado). \n",
    "No upload_collection, você passa um generator (leve).\n",
    "\n",
    "Velocidade: O parâmetro parallel=N no upload_collection é o que realmente faz a diferença em larga escala, pois abre múltiplas conexões simultâneas com o servidor Qdrant.\n",
    "\n",
    "Configuração do Servidor: Note que no início usamos on_disk=True. Sem isso, se você tentar subir 100 milhões de pontos, o servidor Qdrant vai dar erro de Out of Memory (OOM), independentemente de quão bom seja seu código Python."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
